
# Craw recruit data on TOPCV 

# Requirements:
- requests
- beautifulsoup4
# Crawl data
- Open folder withterminal, type `python3 crawler.py a b`( `a`, `b` are the index of begin and end of webpage want to crawl)
- This command will crawl data from consecutive webpages from page `a` to page `b`
## Default Run
- bash crawler217.sh to crawl all data on first 217 page. Then, we have 44 file .json store data.


